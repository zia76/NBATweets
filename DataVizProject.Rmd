###Twitter Sentiment Analysis

#####by Kaleem Khwaja

========================================================

I already had the AFINN sentiment analysis word list, but it includes only 2477 words vs 10K words in the labMT list. The labMT list is scored on a 1-10 scale, and I want to standardize it so that sums of word scores per tweet would be more meaningful: length of tweet would not influence score if standardized, otherwise it would.

```{r echo=FALSE, Load_the_Data}
df <- read.csv("labMT.txt", header=TRUE, sep="\t")
summary(df)
```
 
remove columns other than the happiness_average, and export as csv:
 
```{r echo=FALSE, Choose_the_Columns, export}
df <- df[,c(1,3)]
summary(df)
write.csv(file="labMTstandardized.csv",x=df)
```

While I'm at it, standardize AFINN scores too:

```{r echo=FALSE, AFINN}
df <- read.csv("AFINN-111.txt", header=FALSE, sep="\t")
summary(df)
df$V2 <- scale(df$V2)
names(df)[1] <- "word" #rename columns b4 export
names(df)[2] <- "sentiment_score"
write.csv(file="AFINN-111_standardized.csv",x=df)
```

Now I need to take my csv file (stateFIPS.csv) that maps state and state abbreviation to FIPS codes and merge it with my state and sentiment score csv for d3 mapping.

```{r echo=FALSE, FIPS_codes}

```